\documentclass[13pt]{article}
\usepackage{amsmath}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage{amssymb}
\geometry{vscale=0.95,centering}

\usepackage[absolute,overlay]{textpos}
  \setlength{\TPHorizModule}{1mm}
  \setlength{\TPVertModule}{1mm}

\begin{document}
\title{Feuille de formules \\ Processus Stochastique \\ ACT-2009}
\author{Nicholas langevin}

\maketitle

\section*{Chapitre 2}

\subsubsection*{Propri\'et\'e des cha\^ine de markov}
\[ P( X_{n+1} = j|X_n = i, X_{n-1} = i_{n-1}, ... ,x_1 = i_1, x_0 = i_0) = P(X_{n+1} = j|X_n = i) \]
i.e. seulement le dernier \'etat est d\'eterminant.

\subsubsection*{Chaine de markov homogène}
\[ P(X_{n+1} = j|X_n = i) = p_{ij} \]

\subsubsection*{\'Equation de Chapman-Kolmogorov}
\[ p_{ij}^{(n+m)} = \sum_{k=0}^\infty p_{ik}^{(n)} p_{kj}^{(m)} \]

\subsubsection*{Probabilité non-conditionelle}
\[ P(X_n = j) = \sum_{i=0}^\infty p_{ij}^{(n)} p_{x_0}(i) \]

\subsection*{Classification des états}

\subsubsection*{Accessibles}
j est accessibles à partir de i si: $p_{ij}^{(n)} > 0$

\subsubsection*{Communicants}
i et j sont accessibles réciproqument: $i \leftrightarrow j$

\subsubsection*{Propriétés des états Communicants}
\begin{enumerate}
  \item Réflexibilité: L'états i communique toujours avec lui même.
  \[ p_{ii}^{(0)} = p(X_0 = i|X_0 = i) = 1 \]
  \item Symétrie: Si l'état i communique avec l'état j, alors j communique avec i.
  \[ i \leftrightarrow j \Leftrightarrow j \leftrightarrow i \]
  \item Transitivité: Si l'état i communique avec l'état j et l'état j communique avec l'état k, alors i communque avec k.
  \[ p_{ik}^{(n+m)} = \sum_{r=0}^\infty p_{ir}^{(n)} p_{rk}^{(m)} \geq p_{ij}^{(n)} p_{jk}^{(m)} > 0\]
\end{enumerate}

\subsubsection*{États récurents(persistants) et transients}
Sois $f_{ii}$ la prob que l'état i revienne éventiellement à cette état, alors 
dans une chaîne de markov homogène l'état i est dit:
\begin{itemize}
  \item Récurrent ssi
  \[ \sum_{n=1}^\infty p_{ii}^{(n)} = \infty \Leftrightarrow f_{ii} = 1 \]
  \item transient ssi
  \[ \sum_{n=1}^\infty p_{ii}^{(n)} < \infty \Leftrightarrow f_{ii} < 1 \]
\end{itemize}
\textbf{Corollaire:} Si l'état i est récurrent et communique avec j, alors j est récurrent \\
\textbf{Note:} La récurence et la transience sont des propriétés de classe. \\ 
\textbf{Note:} Dans une chaîne de markov avec un nombre (m) fini d'état, il existe au moins un état de récurence. \\
\textbf{Note:} Toute chaîne de Markov irréductible avec espace d'état fini n'a que des états récurrent.


\subsubsection*{État absorbant}
Un état récurrent i est dit absorbant ssi $p_{ii} = 1$, c'est a dire si une fois atteint l'état i, on ne peut plus en sortir.

\subsection*{Probabilité limite}

\subsubsection*{Définition 1}
Un état i est dit avoir \textbf{période} d si:
\[ d = P.G.C.D.\{ n \in \mathbb{N}|p_{ii}^{(n)} > 0 \} \]
\textbf{Apériodique:} si $d=1$ l'état i est dite apériodique\\
\textbf{Périodicité:} La période d'un classe est un propriété de classe, i.e. toutes les états d'un même classe on la même période.

\subsubsection*{Définition 2}
Un état i est dit \textbf{positif récurrent} si, à partir de l'état i, le temps moyen de retour 
du processus à l'état  est fini. Autrement, l'état i est nul récurrent.

\subsubsection*{Définition 3}
Un état i est dit être \textbf{ergodique} s’il est à la fois apériodique(def (1)) et positif récurrent(def (2)).

\subsubsection*{Théorème des probabilité stationnaire}
Si la chaîne de markov est \textbf{irréductible} et \textbf{ergodique}, alors $p^n$ converge vers une matrice dont chaque ligne est l'unique distribution stationnaire $\pi$ 
\begin{itemize}
  \item $\lim\limits_{n \to \infty} p_{ij}^{(n)} = \pi_j < \infty \:,\forall j \in \mathbb{N}$ 
  \item $\pi_j = \sum\limits_{i=0}^\infty \pi_i p_{ii} \:,\forall j \in \mathbb{N}$
  \item $\sum\limits_{j=0}^\infty \pi_j = 1$ et $\pi_j$ sont uniques
  \item $p(x_{n} = \pi_j) = \pi_j \:, \forall n,j \in \{0,1,2,... \}$
  \item Sois $\mu_{ii}$, le temps moyen(E[n]) pris par le processuss pour passer de l'état i à l'état i, alors
  \[ \pi_i = \frac{1}{\mu_{ii}} \:,\mu_{ii} = \sum_{n=1}^\infty n f_{ii}^{(n)} \]
\end{itemize}

\subsubsection*{Proportion de temps}
Soit $r_i$ la proportion de temps où le processus dans l'état i, alors 
\[ r_j = \sum_{i=0}^w r_i p_{ii}\:,j=0,1,2,...,w\: \textbf{et} \sum_{i=0}^w r_i = 1 \]
où w est le nombre d'état du processus de Markov \\
\textbf{Note:} Il faut alors trouver l'unique solution du système d'équation linéaire.


\subsection*{Application}

\subsubsection*{Système Bonus-Malus}
\[ p_{ij} = \sum_{k:c(i,k)} p(K = k) \] 
où $k \sim$ loi de probabilité 

\subsubsection*{Processus de branchement}
\[ p(x_{k+1}|x_1 = i) = p(x_k = j)^i = (\pi_j)^i \]


\subsubsection*{Étude de crédit}

\[ f_{ij} = \sum_{k=0}^w p_{ik} f_{kj} = \sum_{n=1}^\infty f_{ij}^{(n)} \]
\[ \sum_{n=1}^\infty p_{ii}^{(n)} = \frac{f_{ii}}{1 - f_{ii}} \]

\section*{Chapitre 3}
\subsection*{Processus de dénombrement}
\subsubsection*{Definition I}
Une processus de dénombrement $\{ N(t);t \geq 0 \}$ est dit être un processus de Poisson avec taux $\lambda > 0$ si:
\begin{enumerate}
  \item N(0) = 0
  \item Le processus a des accroissements indépendant, i.e. pour $0 \leq t_1 \leq t_2 \leq t_3$ les accroissements $[N(t_3) - N(t_2)]$ et $[N(t_2) - N(t_1)]$ 
        sont stochastique indépendant.
  \item Le nombre d'événement d'un interval de n'importe qu'elle interval suit une Poisson($\lambda t$)
        \[ p([N(t-s) - N(s)] = n) = \frac{(\lambda t)^n}{n!} e^{-\lambda t} \]
\end{enumerate}

\subsubsection*{Definition II}
\begin{enumerate}
  \item $N(0) = 0$
  \item Le processus a des accroissements indépendant et stationnaire
  \item $p(N(h) = 1) = \lambda h + o(h)$
  \item $p(N(h) \geq 2) = o(h)$ \\ \\ avec $\lim\limits_{h \to 0} \frac{o(h)}{h} = 0 $
\end{enumerate}

\subsection*{Propriétés}
\begin{itemize}
  \item Sois $T_i$ le temps entre le $i^e - 1$ événement et le $i^e$ événement
        \[ T_1, T_2, ... ,T_i  \sim \text{exp}(\lambda)\: \text{et sont i.i.d} \]
  \item Sois $S_n$ le moment où se produit le $n^e$ événement
        \[ S_n = \sum_{i=1}^n T_i \sim \text{gamma}(n, \lambda) \]
  \item $N(t) \geq n \Leftrightarrow S_n \leq t \Rightarrow  p(S_n \leq t) = p(N(t) \geq n) = \sum\limits_{i = n}^\infty \frac{(\lambda t )}{i!} e^{-\lambda t} $
\end{itemize}

\end{document}