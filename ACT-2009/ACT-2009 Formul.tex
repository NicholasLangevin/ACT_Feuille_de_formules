\documentclass[13pt]{article}
\usepackage{amsmath}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage{amssymb}
\geometry{vscale=0.95,centering}

\usepackage[absolute,overlay]{textpos}
  \setlength{\TPHorizModule}{1mm}
  \setlength{\TPVertModule}{1mm}

\begin{document}
\title{Feuille de formules \\ Processus Stochastique \\ ACT-2009}
\author{Nicholas langevin}

\maketitle

\section*{Chapitre 2}

\subsubsection*{Propri\'et\'e des cha\^ine de markov}
\[ P( X_{n+1} = j|X_n = i, X_{n-1} = i_{n-1}, ... ,x_1 = i_1, x_0 = i_0) = P(X_{n+1} = j|X_n = i) \]
i.e. seulement le dernier \'etat est d\'eterminant.

\subsubsection*{Chaine de markov homogène}
\[ P(X_{n+1} = j|X_n = i) = p_{ij} \]

\subsubsection*{\'Equation de Chapman-Kolmogorov}
\[ p_{ij}^{(n+m)} = \sum_{k=0}^\infty p_{ik}^{(n)} p_{kj}^{(m)} \]

\subsubsection*{Probabilité non-conditionelle}
\[ P(X_n = j) = \sum_{i=0}^\infty p_{ij}^{(n)} p_{x_0}(i) \]

\subsection*{Classification des états}

\subsubsection*{Accessibles}
j est accessibles à partir de i si: $p_{ij}^{(n)} > 0$

\subsubsection*{Communicants}
i et j sont accessibles réciproqument: $i \leftrightarrow j$

\subsubsection*{Propriétés des états Communicants}
\begin{enumerate}
  \item Réflexibilité: L'états i communique toujours avec lui même.
  \[ p_{ii}^{(0)} = p(X_0 = i|X_0 = i) = 1 \]
  \item Symétrie: Si l'état i communique avec l'état j, alors j communique avec i.
  \[ i \leftrightarrow j \Leftrightarrow j \leftrightarrow i \]
  \item Transitivité: Si l'état i communique avec l'état j et l'état j communique avec l'état k, alors i communque avec k.
  \[ p_{ik}^{(n+m)} = \sum_{r=0}^\infty p_{ir}^{(n)} p_{rk}^{(m)} \geq p_{ij}^{(n)} p_{jk}^{(m)} > 0\]
\end{enumerate}

\subsubsection*{États récurents(persistants) et transients}
Sois $f_{ii}$ la prob que l'état i revienne éventiellement à cette état, alors 
dans une chaîne de markov homogène l'état i est dit:
\begin{itemize}
  \item Récurrent ssi
  \[ \sum_{n=1}^\infty p_{ii}^{(n)} = \infty \Leftrightarrow f_{ii} = 1 \]
  \item transient ssi
  \[ \sum_{n=1}^\infty p_{ii}^{(n)} < \infty \Leftrightarrow f_{ii} < 1 \]
\end{itemize}
\textbf{Corollaire:} Si l'état i est récurrent et communique avec j, alors j est récurrent \\
\textbf{Note:} La récurence et la transience sont des propriétés de classe. \\ 
\textbf{Note:} Dans une chaîne de markov avec un nombre (m) fini d'état, il existe au moins un état de récurence. \\
\textbf{Note:} Toute chaîne de Markov irréductible avec espace d'état fini n'a que des états récurrent.


\subsubsection*{État absorbant}
Un état récurrent i est dit absorbant ssi $p_{ii} = 1$, c'est a dire si une fois atteint l'état i, on ne peut plus en sortir.

\subsection*{Probabilité limite}

\subsubsection*{Définition 1}
Un état i est dit avoir période d si:
\[ d = P.G.C.D.\{ n \in \mathbb{N}|p_{ii}{(n)} > 0 \} \]
\textbf{Apériodique:} si $d=1$ l'état i est dite apériodique\\
\textbf{Périodicité:} La période d'un classe est un propriété de classe, i.e. toutes les états d'un même classe on la même période.

\subsubsection*{Définition 2}
Un état i est dit \textbf{positif récurrent} si, à partir de l'état i, le temps moyen de retour 
du processus à l'état  est fini. Autrement, l'état i est nul récurrent.

\subsubsection*{Définition 3}
Un état i est dit être ergodique s’il est à la fois apériodique(def (1)) et positif récurrent(def (3)).

\subsubsection*{Théorème des probabilité stationnaire}
Soit une matrice irréductible et ergodique
\begin{itemize}
  \item $\lim\limits_{x \to \infty} p_{ij}^{(n)} = \pi_j < \infty \:,\forall j \in \mathbb{N}$ 
  \item $\pi_j = \sum\limits_{i=0}^\infty \pi_i p_{ii} \:,\forall j \in \mathbb{N}$
  \item $\sum\limits_{j=0}^\infty \pi_j = 1$ et $\pi_j$ sont uniques
  \item Sois $\mu_{ii}$, le temps moyen pris par le processuss pour passer de l'état i à l'état i, alors
  \[ \pi_i = \frac{1}{\mu_{ii}} \]
\end{itemize}

\subsubsection*{Proportion de temps}
Soit $r_i$ la proportion de temps où le processus dans l'état i, alors 
\[ r_j = \sum_{i=0}^w r_i p_{ii}\:,j=0,1,2,...,w\: \textbf{et} \sum_{i=0}^w r_i = 1 \]
où w est le nombre d'état du processus de Markov \\
\textbf{Note:} Il faut alors trouver l'unique solution du système d'équation linéaire.




\end{document}